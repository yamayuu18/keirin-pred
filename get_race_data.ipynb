{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import platform\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "from typing import BinaryIO\n",
    "from __future__ import annotations"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if platform.system() == 'Windows':\n",
    "    DRIVER_SITE: str = 'chromedriver.exe'\n",
    "else:\n",
    "    DRIVER_SITE: str = '/Applications/chromedriver'\n",
    "CURRENT_DIR: str = 'race_data'\n",
    "ORIGINAL_URL: str = 'https://keirin.netkeiba.com/db/search_result/race.html?word=&start_year=none&start_mon=none&end_year=none&end_mon=none&jyo=&sort=1&submit='\n",
    "PARTICIPANTS_FILENAME: str = 'participants'\n",
    "PARTICIPANTS_HEADER: str = (\n",
    "    '日付, 開催場所, ラウンド, グレード, レースグループ, レース名, 発走時間, 距離, 周回,'\n",
    "    '選手名, 着順, 枠番, 車番, 着差, 上り, 決, SB\\n'\n",
    ")\n",
    "RACE_RESULTS_FILENAME: str = 'race_results'\n",
    "RACE_RESULTS_HEADER: str = (\n",
    "    '日付, 開催場所, ラウンド, グレード, レースグループ, レース名, 発走時間, 距離, 周回,'\n",
    "    '2車複, 2車単, ワイド, 3連複, 3連単\\n'\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "options: Options = Options()\n",
    "options.add_argument('--headless')\n",
    "driver: webdriver.Chrome = webdriver.Chrome(DRIVER_SITE, options=options)\n",
    "# driver: webdriver = webdriver.Chrome(DRIVER_SITE)\n",
    "driver.get(ORIGINAL_URL)\n",
    "sleep(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def end_page_correction(driver: webdriver.Chrome, end_page_num: int) -> int:\n",
    "    # 全ページ数の取得\n",
    "    driver.find_element_by_link_text('最後').click()\n",
    "    sleep(1)\n",
    "    total_page_num: int = int(driver.find_element_by_xpath('//a[@class=\"Page_Active\"]').text)\n",
    "    driver.get(ORIGINAL_URL)\n",
    "    sleep(1)\n",
    "\n",
    "    # Webスクレイピング終了ページの補正\n",
    "    if end_page_num > total_page_num:\n",
    "        end_page_num: int = total_page_num\n",
    "\n",
    "    return end_page_num"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def start_page_transition(driver: webdriver.Chrome, start_page_num: int) -> None:\n",
    "    if start_page_num > 1:\n",
    "        for _ in range(1, start_page_num):\n",
    "            driver.find_element_by_link_text('次へ').click()\n",
    "            sleep(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_date_and_venue(soup: BeautifulSoup) -> list[tuple[str]]:\n",
    "    \n",
    "    date_and_venue: list[tuple[str]] = []\n",
    "\n",
    "    # 開催日と開催場所の取得\n",
    "    for data in soup.find_all(class_ = 'DataBox_01'):\n",
    "        (date, venue) = data.p.get_text(strip=True).split()\n",
    "        date_and_venue.append((date, venue))\n",
    "\n",
    "    return date_and_venue"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def date_split(date_str: str, date_term: int) -> list[str]:\n",
    "\n",
    "    dates: list[str] = []\n",
    "    \n",
    "    date_split: list[str] = date_str.split('～')\n",
    "    dates.append(date_split[0])\n",
    "    tdate: datetime = datetime.strptime(date_split[0], '%Y/%m/%d')\n",
    "\n",
    "    for _ in range(1, date_term):\n",
    "        tdate += timedelta(days=1)\n",
    "        dates.append(datetime.strftime(tdate, '%Y/%m/%d'))\n",
    "\n",
    "    return dates\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_race_basic_data(soup: BeautifulSoup) -> list[str]:\n",
    "\n",
    "    race_base_info: list[str] = []\n",
    "\n",
    "    # ラウンド、グレード、レースグループ、レース名、発走時間、距離、周回の取得\n",
    "    race_base_info.append(soup.find(class_ = 'Race_Num').get_text(strip=True))\n",
    "    race_base_info.append(soup.find(class_ = 'Icon_GradeType').get_text(strip=True))\n",
    "    race_base_info.append(soup.find(class_ = 'Race_GroupName').get_text(strip=True))\n",
    "    race_base_info.append(soup.find(class_ = 'Race_Name').get_text(strip=True))\n",
    "    for i, data in enumerate(soup.find(class_ = 'Race_Data').get_text(strip=True).split()):\n",
    "        if i == 1 or i == 4 or i == 5:\n",
    "            race_base_info.append(data)\n",
    "\n",
    "    return race_base_info"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_participants(soup: BeautifulSoup) -> list[list[str]]:\n",
    "    \n",
    "    participants: list[list[str]] = []\n",
    "\n",
    "    # 選手名、着差、上り、決、SBの取得\n",
    "    for player_info in soup.find_all('tr', attrs={'class', 'PlayerList'}):\n",
    "        participant: list[str] = []\n",
    "        participant.append(player_info.find(class_ = 'Player01').get_text(strip=True))\n",
    "        for race_info in player_info.find_all('td', attrs={'class', 'RaceCardCell01'}):\n",
    "            participant.append(race_info.get_text(strip=True))\n",
    "        participants.append(participant)\n",
    "\n",
    "    return participants"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_race_result(soup: BeautifulSoup) -> list[str]:\n",
    "    \n",
    "    race_result: list[str] = []\n",
    "\n",
    "    # 2車複の取得\n",
    "    result_str: str = ''\n",
    "    for i, result in enumerate(soup.find_all(class_ = 'Umaren')):\n",
    "        if i == 0:\n",
    "            result_str += result.find(class_ = 'Result').get_text(strip=True)\n",
    "        else:\n",
    "            result_str += ';' + result.find(class_ = 'Result').get_text(strip=True)\n",
    "    race_result.append(result_str)\n",
    "\n",
    "    # 2車単の取得\n",
    "    result_str: str = ''\n",
    "    for i, result in enumerate(soup.find_all(class_ = 'Umatan')):\n",
    "        if i == 0:\n",
    "            result_str += result.find(class_ = 'Result').get_text(strip=True)\n",
    "        else:\n",
    "            result_str += ';' + result.find(class_ = 'Result').get_text(strip=True)\n",
    "    race_result.append(result_str)\n",
    "\n",
    "    # ワイドの取得\n",
    "    result_str: str = ''\n",
    "    for i, result in enumerate(soup.find_all(class_ = 'Wide')):\n",
    "        if i == 0:\n",
    "            result_str += result.find(class_ = 'Result').get_text(strip=True)\n",
    "        else:\n",
    "            result_str += ';' + result.find(class_ = 'Result').get_text(strip=True)\n",
    "    race_result.append(result_str)\n",
    "\n",
    "    # 3連複の取得\n",
    "    result_str: str = ''\n",
    "    for i, result in enumerate(soup.find_all(class_ = 'Fuku3')):\n",
    "        if i == 0:\n",
    "            result_str += result.find(class_ = 'Result').get_text(strip=True)\n",
    "        else:\n",
    "            result_str += ';' + result.find(class_ = 'Result').get_text(strip=True)\n",
    "    race_result.append(result_str)\n",
    "\n",
    "    # 3連単の取得\n",
    "    result_str: str = ''\n",
    "    for i, result in enumerate(soup.find_all(class_ = 'Tan3')):\n",
    "        if i == 0:\n",
    "            result_str += result.find(class_ = 'Result').get_text(strip=True)\n",
    "        else:\n",
    "            result_str += ';' + result.find(class_ = 'Result').get_text(strip=True)\n",
    "    race_result.append(result_str)\n",
    "\n",
    "    return race_result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def date_and_race_page_scraping(driver,\n",
    "                                date_and_venue: tuple[str],\n",
    "                                participants_file: BinaryIO,\n",
    "                                race_results_file: BinaryIO) -> None:\n",
    "\n",
    "    # レース一覧ページのURLの取得\n",
    "    date_and_race_url: str = driver.current_url\n",
    "\n",
    "    # 開催日リンクの取得\n",
    "    date_list = driver.find_elements_by_xpath('//div[@class=\"Tab_RaceDaySelect p00\"]/ul/li/a')\n",
    "\n",
    "    # 日付の分割\n",
    "    dates: list[str] = date_split(date_and_venue[0], len(date_list))\n",
    "\n",
    "    # 開催日単位での処理\n",
    "    for date_count in range(len(date_list)):\n",
    "\n",
    "        # 開催日リンクの取得(古いセッション参照対応用)\n",
    "        trans_date_list = driver.find_elements_by_xpath('//div[@class=\"Tab_RaceDaySelect p00\"]/ul/li/a')\n",
    "\n",
    "        # 開催日ページへの遷移\n",
    "        trans_date_list[date_count].click()\n",
    "        sleep(1)\n",
    "\n",
    "        # 開催日単位レース詳細ページ要素の取得(古いセッション参照対応用)\n",
    "        date_and_race_list = driver.find_elements_by_xpath('//div[@class=\"RaceList_SlideBoxItem\"]')\n",
    "\n",
    "        # 開催日単位レース詳細ページリンクの取得\n",
    "        race_list = date_and_race_list[date_count].find_elements_by_tag_name('a')\n",
    "\n",
    "        # レース詳細ページ単位での処理\n",
    "        for race_num in range(len(race_list)):\n",
    "            # 開催日単位レース詳細ページ要素の取得(古いセッション参照対応用)\n",
    "            trans_date_and_race_list = driver.find_elements_by_xpath('//div[@class=\"RaceList_SlideBoxItem\"]')\n",
    "\n",
    "            # 開催日単位レース詳細ページリンクの取得(古いセッション参照対応用)\n",
    "            trans_race_list = trans_date_and_race_list[date_count].find_elements_by_tag_name('a')\n",
    "\n",
    "            # レース詳細ページへの遷移\n",
    "            trans_race_list[race_num].click()\n",
    "            sleep(1)\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            # レース基本データの取得\n",
    "            race_basic_data: list[str] = get_race_basic_data(soup)\n",
    "\n",
    "            # 出場選手データの取得\n",
    "            participants: list[list[str]] = get_participants(soup)\n",
    "\n",
    "            # レース結果データの取得\n",
    "            race_result: list[str] = get_race_result(soup)\n",
    "\n",
    "            for participant in participants:\n",
    "                participants_file.write(\n",
    "                    dates[date_count] + \n",
    "                    ',' + date_and_venue[1] + \n",
    "                    ',' + ','.join(race_basic_data) + \n",
    "                    ',' + ','.join(participant) + '\\n'\n",
    "                )\n",
    "\n",
    "            race_results_file.write(\n",
    "                dates[date_count] + \n",
    "                ',' + date_and_venue[1] + \n",
    "                ',' + ','.join(race_basic_data) + \n",
    "                ',' + ','.join(race_result) + '\\n'\n",
    "            )\n",
    "\n",
    "            # レース一覧ページへ戻る\n",
    "            driver.get(date_and_race_url)\n",
    "            sleep(1)\n",
    "            # 開催日ページへの遷移\n",
    "            trans_date_list = driver.find_elements_by_xpath('//div[@class=\"Tab_RaceDaySelect p00\"]/ul/li/a')\n",
    "            trans_date_list[date_count].click()\n",
    "            sleep(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "try:\n",
    "    # Webスクレイピング開始・終了ページの設定\n",
    "    start_page_num: int = 21\n",
    "    end_page_num: int = 100\n",
    "    \n",
    "    # Webスクレイピング終了ページの補正\n",
    "    end_page_num: int = end_page_correction(driver, end_page_num)\n",
    "\n",
    "    # Webスクレイピング開始ページへの遷移\n",
    "    start_page_transition(driver, start_page_num)\n",
    "\n",
    "    race_group_url: str = driver.current_url\n",
    "\n",
    "    for page_num in tqdm(range(start_page_num, end_page_num + 1)):\n",
    "        participants_file = open(os.path.join(CURRENT_DIR, PARTICIPANTS_FILENAME + str(page_num) + '.csv'), 'w')\n",
    "        participants_file.write(PARTICIPANTS_HEADER)\n",
    "\n",
    "        race_results_file = open(os.path.join(CURRENT_DIR, RACE_RESULTS_FILENAME + str(page_num) + '.csv'), 'w')\n",
    "        race_results_file.write(RACE_RESULTS_HEADER)\n",
    "\n",
    "        # 開催日と開催場所の取得\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        date_and_venue: list[tuple[str]] = get_date_and_venue(soup)\n",
    "        \n",
    "        # レースグループリンクの取得\n",
    "        race_group_list = driver.find_elements_by_xpath('//ul[@class=\"CommonList_01\"]/li/div/a')\n",
    "\n",
    "        # レースグループ単位での処理\n",
    "        for race_group_count in range(len(race_group_list)):\n",
    "            # レース一覧ページへの遷移\n",
    "            trans_race_group_list = driver.find_elements_by_xpath('//ul[@class=\"CommonList_01\"]/li/div/a')\n",
    "            trans_race_group_list[race_group_count].click()\n",
    "            sleep(1)\n",
    "\n",
    "            # レース一覧ページのWebスクレイピング\n",
    "            date_and_race_page_scraping(driver,\n",
    "                                        date_and_venue[race_group_count],\n",
    "                                        participants_file,\n",
    "                                        race_results_file)\n",
    "\n",
    "            # レースグループ一覧ページへ戻る\n",
    "            driver.get(race_group_url)\n",
    "            sleep(1)\n",
    "\n",
    "        # 次のレースグループ一覧ページへ遷移する\n",
    "        if page_num < end_page_num:\n",
    "            driver.find_element_by_link_text('次へ').click()\n",
    "            sleep(1)\n",
    "            race_group_url: str = driver.current_url\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print('エラー発生!')\n",
    "    print(driver.current_url)\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    participants_file.close()\n",
    "    race_results_file.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "driver.quit()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "338712a1dc538efa988d8e50f9c1d74b2c319036a17b8257df2c758041ec3584"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}